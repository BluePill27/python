{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv('features/features.csv', index_col='match_id')\n",
    "features.drop('duration radiant_win tower_status_radiant tower_status_dire barracks_status_radiant barracks_status_dire'.split(' '), inplace=True, axis=1)\n",
    "\n",
    "features_test = pd.read_csv('features_test/features_test.csv', index_col='match_id')\n",
    "\n",
    "f_win = pd.read_csv('features/features.csv', index_col='match_id')['radiant_win'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "def XY_tt(features, features_test):\n",
    "    X_train , Y_train = features.fillna(0).as_matrix().astype(float), f_win.as_matrix().astype(float)\n",
    "    X_test = features_test.fillna(0).as_matrix().astype(float)\n",
    "    return scale(X_train), Y_train, scale(X_test)\n",
    "X_train , Y_train, X_test = XY_tt(features, features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (C). Какое наилучшее качество у вас получилось? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Testing_grid(X_train, Y_train, c=[10.0 ** i for i in range(-9, 8)]):\n",
    "    X_train = scale(X_train)\n",
    "    \n",
    "    grid = {'C': c}\n",
    "    clf = LogisticRegression(penalty='l2')\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    gs = GridSearchCV(clf, scoring='roc_auc', param_grid=grid, cv=cv, return_train_score=True)\n",
    "    gs.fit(X_train,Y_train)\n",
    "    print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "    \n",
    "    means = gs.cv_results_['mean_test_score']\n",
    "    stds = gs.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    return c[np.argmax(means)], max(means)\n",
    "    \n",
    "def Testing_cross(X_train, Y_train, c=[10.0 ** i for i in range(-9, 8)]):     \n",
    "    start_time = datetime.datetime.now()\n",
    "    scores=[]\n",
    "    X_train = scale(X_train)\n",
    "    for x in c:\n",
    "        #print (x)\n",
    "        scores.append(np.array(cross_val_score(LogisticRegression(C=x), X_train, Y_train, scoring='roc_auc', cv=cv)))\n",
    "    scores=np.array(scores)\n",
    "    print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "    print (c[np.argmax([np.mean(sc) for sc in scores])])\n",
    "    return c[np.argmax([np.mean(sc) for sc in scores])], max([np.mean(sc) for sc in scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:02:52.302299\n",
      "0.687 (+/-0.003) for {'C': 1e-09}\n",
      "0.687 (+/-0.003) for {'C': 1e-08}\n",
      "0.687 (+/-0.003) for {'C': 1e-07}\n",
      "0.688 (+/-0.003) for {'C': 1e-06}\n",
      "0.695 (+/-0.003) for {'C': 1e-05}\n",
      "0.711 (+/-0.003) for {'C': 0.0001}\n",
      "0.716 (+/-0.003) for {'C': 0.001}\n",
      "0.717 (+/-0.002) for {'C': 0.01}\n",
      "0.717 (+/-0.002) for {'C': 0.1}\n",
      "0.717 (+/-0.002) for {'C': 1.0}\n",
      "0.717 (+/-0.002) for {'C': 10.0}\n",
      "0.717 (+/-0.002) for {'C': 100.0}\n",
      "0.717 (+/-0.002) for {'C': 1000.0}\n",
      "0.717 (+/-0.002) for {'C': 10000.0}\n",
      "0.717 (+/-0.002) for {'C': 100000.0}\n",
      "0.717 (+/-0.002) for {'C': 1000000.0}\n",
      "0.717 (+/-0.002) for {'C': 10000000.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01, 0.71655026972591407)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_grid(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший вариант параметра C = 0.01, при максимальном качестве в 0.71655026972591407. Работает он сильно быстрее, 2 минуты против 4 часов на бустинге, при чуть большем качестве 0.71743541511155817. Очевидно, что бустинг на композиции алгоритмов работает дольше, но зависит от глубины и кол-ва деревьев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2.Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Изменилось ли качество? Чем вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Dell_cat(data_r):\n",
    "    data = data_r.copy()\n",
    "    \n",
    "    todell=[]\n",
    "    \n",
    "    for ind, name in enumerate(data.columns):\n",
    "        if len(data[name].unique())<150 and name.split('_')[1] in ['hero', 'type', 'xp', 'lh']:\n",
    "            #print (name, ind, len(data[name].unique()))\n",
    "            todell.append(name)\n",
    "    return data.drop(todell, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train, X_test = XY_tt(Dell_cat(features), Dell_cat(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:02:14.948020\n",
      "0.679 (+/-0.003) for {'C': 1e-09}\n",
      "0.679 (+/-0.003) for {'C': 1e-08}\n",
      "0.679 (+/-0.003) for {'C': 1e-07}\n",
      "0.680 (+/-0.003) for {'C': 1e-06}\n",
      "0.686 (+/-0.003) for {'C': 1e-05}\n",
      "0.704 (+/-0.003) for {'C': 0.0001}\n",
      "0.714 (+/-0.003) for {'C': 0.001}\n",
      "0.715 (+/-0.003) for {'C': 0.01}\n",
      "0.715 (+/-0.003) for {'C': 0.1}\n",
      "0.715 (+/-0.003) for {'C': 1.0}\n",
      "0.715 (+/-0.003) for {'C': 10.0}\n",
      "0.715 (+/-0.003) for {'C': 100.0}\n",
      "0.715 (+/-0.003) for {'C': 1000.0}\n",
      "0.715 (+/-0.003) for {'C': 10000.0}\n",
      "0.715 (+/-0.003) for {'C': 100000.0}\n",
      "0.715 (+/-0.003) for {'C': 1000000.0}\n",
      "0.715 (+/-0.003) for {'C': 10000000.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1, 0.71513701451769263)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_grid(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Провел быстрые испытания по признакам содежащим 'level', 'item','lh' это ухудшило предсказания. Но если убрать только - 'hero' и 'type', то очевидно, что это практически не повлияет на качество алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясните из данных, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Compare(features, f_win):\n",
    "    data = features.copy()\n",
    "    data['radiant_win'] = f_win\n",
    "    h_col = list(filter(lambda name: name.split('_')[1]=='hero' ,data.columns))\n",
    "    results=[]\n",
    "    for player in h_col:\n",
    "        #for match in data.index:\n",
    "        for hero in data[player].unique():\n",
    "            if player.split('_')[0] in ['r1', 'r2', 'r3', 'r4', 'r5']:\n",
    "                results.append(np.array([hero, player.split('_')[0] ,int(data[(data[player] == hero) & (data['radiant_win']==1)]['radiant_win'].count())]))\n",
    "            else:\n",
    "                results.append(np.array([hero, player.split('_')[0] ,int(data[(data[player] == hero) & (data['radiant_win']==0)]['radiant_win'].count())]))\n",
    "    results = pd.DataFrame(results, columns=['Hero', 'Player', 'Win_count'])\n",
    "    results['Win_count']= results['Win_count'].astype(int)\n",
    "    return results.sort_values(by=['Win_count'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hero</th>\n",
       "      <th>Player</th>\n",
       "      <th>Win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>r1</td>\n",
       "      <td>2795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>7</td>\n",
       "      <td>r5</td>\n",
       "      <td>2395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>11</td>\n",
       "      <td>r2</td>\n",
       "      <td>2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>7</td>\n",
       "      <td>r4</td>\n",
       "      <td>2366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>7</td>\n",
       "      <td>r3</td>\n",
       "      <td>2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>7</td>\n",
       "      <td>r2</td>\n",
       "      <td>2172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>7</td>\n",
       "      <td>d5</td>\n",
       "      <td>2130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>7</td>\n",
       "      <td>d4</td>\n",
       "      <td>2105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>7</td>\n",
       "      <td>d3</td>\n",
       "      <td>2076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>11</td>\n",
       "      <td>r3</td>\n",
       "      <td>2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>50</td>\n",
       "      <td>r5</td>\n",
       "      <td>2063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>11</td>\n",
       "      <td>d1</td>\n",
       "      <td>2062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>11</td>\n",
       "      <td>r4</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7</td>\n",
       "      <td>r1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>112</td>\n",
       "      <td>r5</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hero Player  Win_count\n",
       "0     11     r1       2795\n",
       "479    7     r5       2395\n",
       "135   11     r2       2367\n",
       "335    7     r4       2366\n",
       "222    7     r3       2233\n",
       "136    7     r2       2172\n",
       "980    7     d5       2130\n",
       "865    7     d4       2105\n",
       "783    7     d3       2076\n",
       "233   11     r3       2073\n",
       "457   50     r5       2063\n",
       "605   11     d1       2062\n",
       "378   11     r4       2008\n",
       "34     7     r1       2006\n",
       "443  112     r5       1981"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = Compare(features, f_win)\n",
    "tmp.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если выбирать из top15 по количеству побед, можно заметить, что чаще всего выигрывают за 11 и 7 героя. Хотя, если убрать привзяку к игроку, то можно получить следующий результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Win_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hero</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>17912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>17662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>17617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Win_count\n",
       "Hero           \n",
       "7         21306\n",
       "11        19766\n",
       "112       17912\n",
       "50        17662\n",
       "72        17617"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[['Hero', 'Win_count']].groupby(['Hero']).sum().sort_values('Win_count', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши ожидания подтвердились, также можно заметить и других героев, игра с которомы ведет к победе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Bag_words(features):\n",
    "    data = features.copy()\n",
    "    \n",
    "    N = data['r1_hero'].max()\n",
    "    \n",
    "    # N — количество различных героев в выборке\n",
    "    X_pick = np.zeros((data.shape[0], N))\n",
    "    \n",
    "    for i, match_id in enumerate(data.index):\n",
    "        for p in range(1, 6):\n",
    "            X_pick[i, data.loc[match_id, 'r%d_hero' % p]-1] = 1\n",
    "            X_pick[i, data.loc[match_id, 'd%d_hero' % p]-1] = -1\n",
    "    results = pd.DataFrame(X_pick, columns=['Bhero_'+str(i) for i in range(1, N+1)], index = data.index)\n",
    "    return pd.concat([data, results], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "X_train , Y_train, X_test = XY_tt(Dell_cat(Bag_words(features)), Dell_cat(Bag_words(features_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Какое получилось качество? Улучшилось ли оно? Чем вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:04:44.954659\n",
      "0.700 (+/-0.003) for {'C': 1e-09}\n",
      "0.700 (+/-0.003) for {'C': 1e-08}\n",
      "0.701 (+/-0.003) for {'C': 1e-07}\n",
      "0.702 (+/-0.003) for {'C': 1e-06}\n",
      "0.715 (+/-0.003) for {'C': 1e-05}\n",
      "0.743 (+/-0.004) for {'C': 0.0001}\n",
      "0.752 (+/-0.005) for {'C': 0.001}\n",
      "0.752 (+/-0.005) for {'C': 0.01}\n",
      "0.752 (+/-0.005) for {'C': 0.1}\n",
      "0.752 (+/-0.005) for {'C': 1.0}\n",
      "0.752 (+/-0.005) for {'C': 10.0}\n",
      "0.752 (+/-0.005) for {'C': 100.0}\n",
      "0.752 (+/-0.005) for {'C': 1000.0}\n",
      "0.752 (+/-0.005) for {'C': 10000.0}\n",
      "0.752 (+/-0.005) for {'C': 100000.0}\n",
      "0.752 (+/-0.005) for {'C': 1000000.0}\n",
      "0.752 (+/-0.005) for {'C': 10000000.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01, 0.75196404316175602)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_grid(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить заметное улучшение качества. Раньше информация о героях не несла никакого смысла, теперь каждый герой осмысленее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации). Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой (т.е. что модель не получилась константной)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l2', C=0.01)\n",
    "clf.fit(X_train, Y_train)\n",
    "win = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([[match, win[ind][1]] for ind, match in enumerate(features_test.index)], columns=['match_id', 'radiant_win']).to_csv('result.scv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max 0.98260417143\n",
      "Min 0.00336830843809\n"
     ]
    }
   ],
   "source": [
    "print('Max', pd.DataFrame([[match, win[ind][1]] for ind, match in enumerate(features_test.index)], columns=['match_id', 'radiant_win'])['radiant_win'].max())\n",
    "print('Min', pd.DataFrame([[match, win[ind][1]] for ind, match in enumerate(features_test.index)], columns=['match_id', 'radiant_win'])['radiant_win'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score 0.75522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=2, max_depth=4)\n",
    "clf.fit(X_train, Y_train)\n",
    "win = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([[match, win[ind][1]] for ind, match in enumerate(features_test.index)], columns=['match_id', 'radiant_win']).to_csv('result.scv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Был интерес, но Score 0.62232."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
