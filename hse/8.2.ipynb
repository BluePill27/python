{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите выборку из файла gbm-data.csv с помощью pandas и преобразуйте ее в массив numpy (параметр values у датафрейма). В первой колонке файла с данными записано, была или нет реакция. Все остальные колонки (d1 - d1776) содержат различные характеристики молекулы, такие как размер, форма и т.д. Разбейте выборку на обучающую и тестовую, используя функцию train_test_split с параметрами test_size = 0.8 и random_state = 241."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('gbm-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:1777].values\n",
    "y = data.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.8, random_state = 241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите GradientBoostingClassifier с параметрами n_estimators=250, verbose=True, random_state=241 и для каждого значения learning_rate из списка [1, 0.5, 0.3, 0.2, 0.1] проделайте следующее:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Используйте метод staged_decision_function для предсказания качества на обучающей и тестовой выборке на каждой итерации.\n",
    "- Преобразуйте полученное предсказание с помощью сигмоидной функции по формуле 1 / (1 + e^{−y_pred}), где y_pred — предсказанное значение.\n",
    "- Вычислите и постройте график значений log-loss (которую можно посчитать с помощью функции sklearn.metrics.log_loss) на обучающей и тестовой выборках, а также найдите минимальное значение метрики и номер итерации, на которой оно достигается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(y_pred):\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred[i] = 1. / (1 + np.exp(-y_pred[i])) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0190           15.44s\n",
      "         2           0.9192           15.50s\n",
      "         3           0.8272           14.16s\n",
      "         4           0.7834           14.14s\n",
      "         5           0.7109           13.08s\n",
      "         6           0.6368           13.58s\n",
      "         7           0.5797           13.23s\n",
      "         8           0.5610           12.95s\n",
      "         9           0.5185           13.09s\n",
      "        10           0.4984           12.74s\n",
      "        20           0.1999           11.51s\n",
      "        30           0.1313           10.86s\n",
      "        40           0.0790           10.91s\n",
      "        50           0.0511           10.29s\n",
      "        60           0.0352            9.66s\n",
      "        70           0.0245            9.00s\n",
      "        80           0.0162            8.43s\n",
      "        90           0.0114            8.04s\n",
      "       100           0.0077            7.50s\n",
      "       200           0.0004            2.19s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1255           18.92s\n",
      "         2           1.0035           18.23s\n",
      "         3           0.9386           18.03s\n",
      "         4           0.8844           17.16s\n",
      "         5           0.8381           16.51s\n",
      "         6           0.7995           15.05s\n",
      "         7           0.7559           14.48s\n",
      "         8           0.7205           14.04s\n",
      "         9           0.6958           14.17s\n",
      "        10           0.6725           13.68s\n",
      "        20           0.4672           11.60s\n",
      "        30           0.3179           11.27s\n",
      "        40           0.2274           10.54s\n",
      "        50           0.1774           10.20s\n",
      "        60           0.1394            9.58s\n",
      "        70           0.1050            9.16s\n",
      "        80           0.0805            8.54s\n",
      "        90           0.0650            7.93s\n",
      "       100           0.0511            7.54s\n",
      "       200           0.0058            2.38s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2095           11.70s\n",
      "         2           1.1006           13.52s\n",
      "         3           1.0240           12.84s\n",
      "         4           0.9729           13.59s\n",
      "         5           0.9387           13.13s\n",
      "         6           0.8948           12.81s\n",
      "         7           0.8621           12.57s\n",
      "         8           0.8360           12.37s\n",
      "         9           0.8171           12.56s\n",
      "        10           0.7883           12.41s\n",
      "        20           0.6164           12.60s\n",
      "        30           0.4933           11.93s\n",
      "        40           0.4248           10.72s\n",
      "        50           0.3345           10.02s\n",
      "        60           0.2760            9.37s\n",
      "        70           0.2263            8.77s\n",
      "        80           0.1971            8.19s\n",
      "        90           0.1693            7.65s\n",
      "       100           0.1388            7.17s\n",
      "       200           0.0294            2.30s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2613           15.69s\n",
      "         2           1.1715           15.38s\n",
      "         3           1.1009           14.16s\n",
      "         4           1.0529           14.88s\n",
      "         5           1.0130           14.46s\n",
      "         6           0.9740           13.91s\n",
      "         7           0.9475           13.50s\n",
      "         8           0.9197           13.19s\n",
      "         9           0.8979           13.50s\n",
      "        10           0.8730           13.22s\n",
      "        20           0.7207           11.37s\n",
      "        30           0.6055           10.57s\n",
      "        40           0.5244            9.92s\n",
      "        50           0.4501            9.36s\n",
      "        60           0.3908            8.83s\n",
      "        70           0.3372            8.38s\n",
      "        80           0.3009            7.88s\n",
      "        90           0.2603            7.42s\n",
      "       100           0.2327            7.01s\n",
      "       200           0.0835            2.26s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3199           11.70s\n",
      "         2           1.2645           13.52s\n",
      "         3           1.2170           12.84s\n",
      "         4           1.1775           13.84s\n",
      "         5           1.1404           13.18s\n",
      "         6           1.1106           13.50s\n",
      "         7           1.0844           13.43s\n",
      "         8           1.0617           13.49s\n",
      "         9           1.0411           13.44s\n",
      "        10           1.0223           13.54s\n",
      "        20           0.8864           12.04s\n",
      "        30           0.7844           11.04s\n",
      "        40           0.7176           10.26s\n",
      "        50           0.6590            9.62s\n",
      "        60           0.6120            8.99s\n",
      "        70           0.5599            8.51s\n",
      "        80           0.5242            7.97s\n",
      "        90           0.4829            7.50s\n",
      "       100           0.4473            7.01s\n",
      "       200           0.2379            2.26s\n"
     ]
    }
   ],
   "source": [
    "decis=[]\n",
    "for i in [1, 0.5, 0.3, 0.2, 0.1]:\n",
    "    clf = GradientBoostingClassifier(learning_rate=i, n_estimators=250, verbose=True, random_state=241)\n",
    "    clf.fit(X_train, y_train)\n",
    "    decis.append(clf.staged_decision_function(X_test))\n",
    "    pred = clf.predict_proba(X_test)\n",
    "    pred = transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
