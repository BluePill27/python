{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одной из самых простых метрик успешности бизнеса для владельцев кафе и ресторанов является посещаемость их заведения. Это интуитивно понятно - в целом, чем больше клиентов, тем больше прибыль. Соответственно, нужно уметь оценивать этот показатель и понимать, как на него влияют различные параметры, поэтому вам предлагается для решения задача предсказания процента заполненности кафе. В течении дня эта величина может заметно меняться, поэтому приведена информация для обеденного времени в будний день.\n",
    "\n",
    "В данных представлены как характеристики самих заведений, так и описание окружающих их обьектов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание файлов\n",
    "\n",
    "- train.csv - обучающая выборка\n",
    "- test.csv - тестовая выборка\n",
    "- answers_sample.csv - формат для посылки\n",
    "- answers_train.csv - ответы для обучающей выборки\n",
    "\n",
    "# Описание данных\n",
    "\n",
    "- price - средний чек\n",
    "3. lunch - цена ланча\n",
    "4. n_seats - количество посадочных мест\n",
    "5. is_net - индикатор сетевого заведения (1 - сетевое, 0 - уникальное)\n",
    "6. type - тип заведения - кафе, ресторан и так далее\n",
    "7. obj_rayon - район расположения\n",
    "8. sumareaLive, meanareaLive - суммарная и средняя площади (в м2) по жилым обьектам в радиусе 500 метров\n",
    "9. maxareaLive - площадь самого большого жилого обьекта (в м2) в радиусе 500 метров\n",
    "8. sumareaComm, meanareaComm, maxareaComm - параметры для коммерческих обьектов, аналогичные жилым\n",
    "10. places_near_300m - количество ресторанов в радиусе 300 метров\n",
    "11. metro_near_500m - количество станций метро в радиусе 500 метров\n",
    "12. dist_to_metro - расстояние до ближайшей станции метро (в метрах)\n",
    "13. something_300m - количество объектов типа 'something' в радиусе 300 метров (всего 250 признаков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = pd.read_csv('train.csv').replace(-1, np.nan).apply(lambda row: row.fillna(np.mean(row)), axis=1), pd.read_csv('test.csv').replace(-1, np.nan).apply(lambda row: row.fillna(np.mean(row)), axis=1)\n",
    "sample, Y_train = pd.read_csv('answers_sample.csv'), pd.read_csv('answers_train.csv').replace(-1, np.nan).apply(lambda row: row.fillna(np.mean(row)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dist_to_metro, yes - - 4\n",
    "- maxareaCom, no\n",
    "- maxareaLiv, no\n",
    "- meanareaComm, yes - 4\n",
    "- meanareaLive, yes - 4\n",
    "- sumareaCom, no\n",
    "- sumareaLiv, no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test.drop('maxareaComm maxareaLive sumareaComm sumareaLive type'.split(), inplace=True, axis=1)\n",
    "X_train.drop('maxareaComm maxareaLive sumareaComm sumareaLive type'.split(), inplace=True, axis=1)\n",
    "for name in X_train.corr()[lambda x: np.abs(x)>0.7].count()[lambda x: x>6].index:\n",
    "   X_train.drop(name, inplace=True, axis=1)\n",
    "   X_test.drop(name, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clf = KMeans(n_clusters=3, random_state=1)\n",
    "for name in 'dist_to_metro meanareaComm meanareaLive'.split():\n",
    "    Xtr = X_train[name].as_matrix().reshape(-1, 1)\n",
    "    Xt = X_test[name].as_matrix().reshape(-1, 1)\n",
    "    clf.fit(Xtr)\n",
    "    X_train[name] = clf.labels_\n",
    "    clf.fit(Xt)\n",
    "    X_test[name] = clf.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Testing_grid_reg(X_train, Y_train, c=[10.0 ** i for i in range(-9, 8)]):\n",
    "    cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    grid = {'C': c,\n",
    "           'penalty' : ['l1', 'l2']}\n",
    "    clf = LogisticRegression(penalty='l1')\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    gs = GridSearchCV(clf, scoring='neg_mean_absolute_error', param_grid=grid, cv=cv, return_train_score=True)\n",
    "    gs.fit(X_train,Y_train)\n",
    "    print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "    \n",
    "    means = gs.cv_results_['mean_test_score']\n",
    "    stds = gs.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    return max(means), gs.best_params_\n",
    "\n",
    "def Testing_grid_xgb(X_train, Y_train):\n",
    "    cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    clf = xgb.XGBRegressor()        \n",
    "    parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear', 'reg:gamma'],\n",
    "              'learning_rate': [.01,0.05, .004, 0.002], #so called `eta` value\n",
    "              'max_depth': [6, 7, 9],\n",
    "              'min_child_weight': [4, 5, 7],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7, 0.2, 0.1, 0.05],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [150, 250, 350, 450, 500],\n",
    "              'base_score' : [0.5]}\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    gs = GridSearchCV(clf, scoring='neg_mean_absolute_error', param_grid=parameters, cv=cv,  n_jobs = 5, verbose=True)\n",
    "    gs.fit(X_train,Y_train)\n",
    "    print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "    \n",
    "    means = gs.cv_results_['mean_test_score']\n",
    "    stds = gs.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    return max(means), gs.best_params_\n",
    "\n",
    "def Testing_grid_bays(X_train, Y_train):\n",
    "    cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    \n",
    "    clf = BayesianRidge()\n",
    "    grid = {'n_iter' : [500, 800, 1000],\n",
    "        'tol' : [1.0 ** i for i in range(-5, -1)],\n",
    "        'alpha_1' : [1.0 ** i for i in range(-4, 2)],\n",
    "        'alpha_2' : [1.0 ** i for i in range(-4, 2)],\n",
    "        'lambda_1' : [1.0 ** i for i in range(-4, 2)],\n",
    "        'lambda_2' : [1.0 ** i for i in range(-4, 2)],\n",
    "        'fit_intercept' : [True]\n",
    "    }\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    gs = GridSearchCV(clf, scoring='neg_mean_absolute_error', param_grid=grid, cv=cv, return_train_score=True, n_jobs = 5)\n",
    "    gs.fit(X_train,Y_train)\n",
    "    print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "    \n",
    "    means = gs.cv_results_['mean_test_score']\n",
    "    stds = gs.cv_results_['std_test_score']\n",
    "    #for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "        #print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "         #     % (mean, std * 2, params))\n",
    "    return max(means), gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Res_save(X_train, Y_train, X_test,clf):\n",
    "    clf.fit(X_train.as_matrix(), Y_train['answer'].as_matrix())\n",
    "    rez = clf.predict(X_test.as_matrix())\n",
    "    Results = pd.concat([pd.DataFrame(X_test.index), pd.DataFrame(rez)], axis=1)\n",
    "    Results.columns = ['id', 'answer']\n",
    "    Results.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params = Testing_grid_xgb(X_train.as_matrix(), Y_train['answer'].as_matrix())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_score = 0.5 ,\n",
      "colsample_bytree = 0.7 ,\n",
      "learning_rate = 0.05 ,\n",
      "max_depth = 6 ,\n",
      "min_child_weight = 7 ,\n",
      "n_estimators = 350 ,\n",
      "nthread = 4 ,\n",
      "objective = reg:gamma ,\n",
      "silent = 1 ,\n",
      "subsample = 0.1 ,\n"
     ]
    }
   ],
   "source": [
    "for key in params:\n",
    "    print (key,'=',params[key],',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor(base_score = 0.5, \n",
    "                       colsample_bytree = 0.7 ,\n",
    "                       learning_rate = 0.05 ,\n",
    "                       max_depth = 6 ,\n",
    "                       min_child_weight = 7 ,\n",
    "                       n_estimators = 350 ,\n",
    "                       nthread = 4 ,\n",
    "                       objective = 'reg:gamma' ,\n",
    "                       silent = 1 ,\n",
    "                       subsample = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Res_save(X_train, Y_train, X_test, clf=clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=0.001, penalty= 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_grid_reg(X_train.as_matrix(), Y_train['answer'].as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это лучший результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Testing_grid_bays(X_train.as_matrix(), Y_train['answer'].as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = BayesianRidge(alpha_1=1, alpha_2=1, fit_intercept=True, lambda_1 = 1, lambda_2=1, n_iter = 500, tol = 1)\n",
    "Res_save(X_train, Y_train, X_test, clf=clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
