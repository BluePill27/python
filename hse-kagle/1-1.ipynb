{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection._validation import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одной из самых простых метрик успешности бизнеса для владельцев кафе и ресторанов является посещаемость их заведения. Это интуитивно понятно - в целом, чем больше клиентов, тем больше прибыль. Соответственно, нужно уметь оценивать этот показатель и понимать, как на него влияют различные параметры, поэтому вам предлагается для решения задача предсказания процента заполненности кафе. В течении дня эта величина может заметно меняться, поэтому приведена информация для обеденного времени в будний день.\n",
    "\n",
    "В данных представлены как характеристики самих заведений, так и описание окружающих их обьектов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание файлов\n",
    "\n",
    "- train.csv - обучающая выборка\n",
    "- test.csv - тестовая выборка\n",
    "- answers_sample.csv - формат для посылки\n",
    "- answers_train.csv - ответы для обучающей выборки\n",
    "\n",
    "# Описание данных\n",
    "\n",
    "- lon, lat - координаты по долготе и широте\n",
    "2. price - средний чек\n",
    "3. lunch - цена ланча\n",
    "4. n_seats - количество посадочных мест\n",
    "5. is_net - индикатор сетевого заведения (1 - сетевое, 0 - уникальное)\n",
    "6. type - тип заведения - кафе, ресторан и так далее\n",
    "7. obj_rayon - район расположения\n",
    "8. sumareaLive, meanareaLive - суммарная и средняя площади (в м2) по жилым обьектам в радиусе 500 метров\n",
    "9. maxareaLive - площадь самого большого жилого обьекта (в м2) в радиусе 500 метров\n",
    "8. sumareaComm, meanareaComm, maxareaComm - параметры для коммерческих обьектов, аналогичные жилым\n",
    "10. places_near_300m - количество ресторанов в радиусе 300 метров\n",
    "11. metro_near_500m - количество станций метро в радиусе 500 метров\n",
    "12. dist_to_metro - расстояние до ближайшей станции метро (в метрах)\n",
    "13. something_300m - количество объектов типа 'something' в радиусе 300 метров (всего 250 признаков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = pd.read_csv('train.csv').replace(-1, np.nan).apply(lambda row: row.fillna(np.mean(row)), axis=1), pd.read_csv('test.csv').replace(-1, np.nan).apply(lambda row: row.fillna(np.mean(row)), axis=1)\n",
    "sample, Y_train = pd.read_csv('answers_sample.csv'), pd.read_csv('answers_train.csv').replace(-1, np.nan).apply(lambda row: row.fillna(np.mean(row)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dist_to_metro, yes - - 4\n",
    "- maxareaCom, no\n",
    "- maxareaLiv, no\n",
    "- meanareaComm, yes - 4\n",
    "- meanareaLive, yes - 4\n",
    "- sumareaCom, no\n",
    "- sumareaLiv, no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop('maxareaComm maxareaLive sumareaComm sumareaLive'.split(), inplace=True, axis=1)\n",
    "X_train.drop('maxareaComm maxareaLive sumareaComm sumareaLive'.split(), inplace=True, axis=1)\n",
    "for name in X_train.corr()[lambda x: np.abs(x)>0.7].count()[lambda x: x>8].index:\n",
    "   X_train.drop(name, inplace=True, axis=1)\n",
    "   X_test.drop(name, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clf = KMeans(n_clusters=3, random_state=1)\n",
    "for name in 'dist_to_metro meanareaComm meanareaLive'.split():\n",
    "    Xtr = X_train[name].as_matrix().reshape(-1, 1)\n",
    "    Xt = X_test[name].as_matrix().reshape(-1, 1)\n",
    "    clf.fit(Xtr)\n",
    "    X_train[name] = clf.labels_\n",
    "    clf.fit(Xt)\n",
    "    X_test[name] = clf.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Testing_grid_reg(X_train, Y_train, c=[10.0 ** i for i in range(-9, 8)]):\n",
    "    cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    grid = {'C': c,\n",
    "           'penalty' : ['l1', 'l2']}\n",
    "    clf = LogisticRegression(penalty='l1')\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    gs = GridSearchCV(clf, scoring='neg_mean_absolute_error', param_grid=grid, cv=cv, return_train_score=True)\n",
    "    gs.fit(X_train,Y_train)\n",
    "    print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "    \n",
    "    means = gs.cv_results_['mean_test_score']\n",
    "    stds = gs.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    return c[np.argmax(means)], max(means), gs.best_params_\n",
    "\n",
    "def Testing_grid_xgb(X_train, Y_train):\n",
    "    cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    clf = xgb.XGBRegressor()        \n",
    "    parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [0.05, .004, 0.002], #so called `eta` value\n",
    "              'max_depth': [6, 7, 9],\n",
    "              'min_child_weight': [4, 5, 7],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [1000],\n",
    "              'base_score' : [0.5]}\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    gs = GridSearchCV(clf, scoring='neg_mean_absolute_error', param_grid=parameters, cv=cv,  n_jobs = 5, verbose=True)\n",
    "    gs.fit(X_train,Y_train)\n",
    "    print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "    \n",
    "    means = gs.cv_results_['mean_test_score']\n",
    "    stds = gs.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    return max(means), gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Res_save(X_train, Y_train, X_test,clf):\n",
    "    clf.fit(X_train.as_matrix(), Y_train['answer'].as_matrix())\n",
    "    rez = clf.predict(X_test.as_matrix())\n",
    "    Results = pd.concat([pd.DataFrame(X_test.index), pd.DataFrame(rez)], axis=1)\n",
    "    Results.columns = ['id', 'answer']\n",
    "    Results.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=5)]: Done  81 out of  81 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:02:27.062887\n",
      "-17.830 (+/-1.878) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.710 (+/-2.143) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.732 (+/-1.704) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 7, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.764 (+/-2.081) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.494 (+/-2.086) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.427 (+/-2.005) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.915 (+/-2.255) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 9, 'min_child_weight': 4, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.473 (+/-2.360) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.751 (+/-1.994) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.265 (+/-2.220) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.004, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.209 (+/-2.154) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.004, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.155 (+/-2.190) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.004, 'max_depth': 6, 'min_child_weight': 7, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.309 (+/-2.199) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.004, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.235 (+/-2.261) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.004, 'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.152 (+/-2.260) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.004, 'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.356 (+/-2.216) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.004, 'max_depth': 9, 'min_child_weight': 4, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.280 (+/-2.277) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.004, 'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-17.117 (+/-2.361) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.004, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-16.840 (+/-2.527) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.002, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-16.840 (+/-2.503) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.002, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-16.862 (+/-2.530) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.002, 'max_depth': 6, 'min_child_weight': 7, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-16.838 (+/-2.523) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.002, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-16.853 (+/-2.513) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.002, 'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-16.866 (+/-2.509) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.002, 'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-16.818 (+/-2.549) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.002, 'max_depth': 9, 'min_child_weight': 4, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-16.848 (+/-2.508) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.002, 'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
      "-16.866 (+/-2.528) for {'base_score': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.002, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "params = Testing_grid_xgb(X_train.as_matrix(), Y_train['answer'].as_matrix())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_score = 0.5 ,\n",
      "colsample_bytree = 0.7 ,\n",
      "learning_rate = 0.002 ,\n",
      "max_depth = 9 ,\n",
      "min_child_weight = 4 ,\n",
      "n_estimators = 1000 ,\n",
      "nthread = 4 ,\n",
      "objective = reg:linear ,\n",
      "silent = 1 ,\n",
      "subsample = 0.7 ,\n"
     ]
    }
   ],
   "source": [
    "for key in params:\n",
    "    print (key,'=',params[key],',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor(base_score = 0.5, colsample_bytree = 0.7 ,\n",
    "learning_rate = 0.0002 ,\n",
    "max_depth = 9 ,\n",
    "min_child_weight = 4 ,\n",
    "n_estimators = 1000 ,\n",
    "nthread = 4 ,\n",
    "objective = 'reg:linear' ,\n",
    "silent = 1 ,\n",
    "subsample = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:37.039158\n",
      "-25.380 (+/-0.903) for {'C': 1e-09, 'penalty': 'l1'}\n",
      "-20.067 (+/-1.239) for {'C': 1e-09, 'penalty': 'l2'}\n",
      "-25.380 (+/-0.903) for {'C': 1e-08, 'penalty': 'l1'}\n",
      "-20.058 (+/-0.922) for {'C': 1e-08, 'penalty': 'l2'}\n",
      "-25.380 (+/-0.903) for {'C': 1e-07, 'penalty': 'l1'}\n",
      "-20.048 (+/-0.856) for {'C': 1e-07, 'penalty': 'l2'}\n",
      "-25.380 (+/-0.903) for {'C': 1e-06, 'penalty': 'l1'}\n",
      "-20.035 (+/-0.820) for {'C': 1e-06, 'penalty': 'l2'}\n",
      "-19.473 (+/-2.451) for {'C': 1e-05, 'penalty': 'l1'}\n",
      "-20.230 (+/-1.132) for {'C': 1e-05, 'penalty': 'l2'}\n",
      "-19.974 (+/-0.935) for {'C': 0.0001, 'penalty': 'l1'}\n",
      "-20.048 (+/-1.299) for {'C': 0.0001, 'penalty': 'l2'}\n",
      "-20.042 (+/-0.799) for {'C': 0.001, 'penalty': 'l1'}\n",
      "-18.332 (+/-0.568) for {'C': 0.001, 'penalty': 'l2'}\n",
      "-19.399 (+/-1.481) for {'C': 0.01, 'penalty': 'l1'}\n",
      "-18.847 (+/-1.602) for {'C': 0.01, 'penalty': 'l2'}\n",
      "-19.217 (+/-2.718) for {'C': 0.1, 'penalty': 'l1'}\n",
      "-20.272 (+/-2.702) for {'C': 0.1, 'penalty': 'l2'}\n",
      "-21.198 (+/-1.629) for {'C': 1.0, 'penalty': 'l1'}\n",
      "-20.243 (+/-3.778) for {'C': 1.0, 'penalty': 'l2'}\n",
      "-21.361 (+/-0.053) for {'C': 10.0, 'penalty': 'l1'}\n",
      "-20.310 (+/-2.939) for {'C': 10.0, 'penalty': 'l2'}\n",
      "-21.594 (+/-0.716) for {'C': 100.0, 'penalty': 'l1'}\n",
      "-20.204 (+/-2.631) for {'C': 100.0, 'penalty': 'l2'}\n",
      "-21.077 (+/-2.236) for {'C': 1000.0, 'penalty': 'l1'}\n",
      "-20.521 (+/-2.159) for {'C': 1000.0, 'penalty': 'l2'}\n",
      "-20.275 (+/-1.198) for {'C': 10000.0, 'penalty': 'l1'}\n",
      "-20.930 (+/-1.837) for {'C': 10000.0, 'penalty': 'l2'}\n",
      "-20.204 (+/-0.470) for {'C': 100000.0, 'penalty': 'l1'}\n",
      "-20.272 (+/-1.632) for {'C': 100000.0, 'penalty': 'l2'}\n",
      "-20.163 (+/-1.739) for {'C': 1000000.0, 'penalty': 'l1'}\n",
      "-20.438 (+/-2.505) for {'C': 1000000.0, 'penalty': 'l2'}\n",
      "-20.051 (+/-0.950) for {'C': 10000000.0, 'penalty': 'l1'}\n",
      "-20.163 (+/-1.896) for {'C': 10000000.0, 'penalty': 'l2'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000.0, -18.332268370607029, {'C': 0.001, 'penalty': 'l2'})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_grid_reg(X_train.as_matrix(), Y_train['answer'].as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=0.001, penalty= 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Res_save(X_train, Y_train, X_test, clf=clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.1,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'learning_rate': 0.004,\n",
       " 'max_depth': 7,\n",
       " 'min_child_weight': 4,\n",
       " 'n_estimators': 500,\n",
       " 'nthread': 4,\n",
       " 'objective': 'reg:linear',\n",
       " 'silent': 1,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PR-агентство_300m', 'Агентство недвижимости_300m',\n",
       "       'Брокерская компания_300m', 'Железнодорожные и авиабилеты_300m',\n",
       "       'Жильё посуточно_300m', 'Кадровое агентство_300m', 'Кальян-бар_300m',\n",
       "       'Квесты_300m', 'Клуб досуга_300m', 'Косметология_300m',\n",
       "       'Магазин одежды_300m', 'Магазин чая и кофе_300m',\n",
       "       'Музыкальное образование_300m', 'Ногтевая студия_300m',\n",
       "       'Общественная организация_300m', 'Оценочная компания_300m',\n",
       "       'Помощь в оформлении виз и загранпаспортов_300m', 'Пункт выдачи_300m',\n",
       "       'Спортивное объединение_300m', 'Строительные и отделочные работы_300m',\n",
       "       'Студия веб-дизайна_300m', 'Товары для мобильных телефонов_300m',\n",
       "       'Турагентство_300m', 'Туроператор_300m', 'Учебный центр_300m',\n",
       "       'Художественная мастерская_300m', 'Центр йоги_300m',\n",
       "       'Школа танцев_300m', 'Юридические услуги_300m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.corr()[lambda x: np.abs(x)>0.6].count()[lambda x: x>3].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
