{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd, norm, cho_factor, cho_solve\n",
    "import pdb\n",
    "from math import sqrt, log\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADMM(A, y,  iters = 100):\n",
    "    m, n = A.shape\n",
    "    A_t_A = A.T.dot(A)\n",
    "    w, v = np.linalg.eig(A_t_A)\n",
    "\n",
    "    \n",
    "    x_hat = np.zeros([n, 1])\n",
    "    z_hat = np.zeros([n, 1])\n",
    "    u = np.zeros([n, 1])\n",
    "\n",
    "    #Calculate regression co-efficient and stepsize\n",
    "    r = np.amax(np.absolute(w))\n",
    "    l_over_rho = sqrt(2*log(n, 10)) * r / 2.0\n",
    "    rho = 1/r\n",
    "\n",
    "    #Pre-compute to save some multiplications\n",
    "    A_t_y = A.T.dot(y)\n",
    "    Q = A_t_A + rho * np.identity(n)\n",
    "    Q = np.linalg.inv(Q)\n",
    "    Q_dot = Q.dot\n",
    "    maximum = np.maximum\n",
    "\n",
    "    for irt in trange(iters):\n",
    "        #x minimisation step via posterier OLS\n",
    "        x_hat = Q_dot(A_t_y + rho*(1/irt*z_hat - u))\n",
    "        #z minimisation via soft-thresholding\n",
    "        u = x_hat + u\n",
    "        z_hat = u *  np.maximum(0,  np.absolute(u)-l_over_rho)\n",
    "        #mulitplier update\n",
    "        u = u - z_hat\n",
    "\n",
    "    return z_hat\n",
    "\n",
    "def subgradient(A, x, iters = 100):\n",
    "    x_init = x\n",
    "    vals = []\n",
    "    i = np.random.randint(0, N)\n",
    "    for iter_i in trange(iters):\n",
    "        i = np.random.randint(0, N)\n",
    "    \n",
    "        dot = np.dot(a[i], x_cur)\n",
    "    \n",
    "        if dot >= 1 and len(vals) > 0:\n",
    "            vals.append(vals[-1])\n",
    "            continue\n",
    "        \n",
    "        sub_grad = -a[i]\n",
    "        eta = 1 / np.sqrt(m * (iter_i+1))    \n",
    "        x_raw = x_cur - eta * sub_grad\n",
    "    \n",
    "        x_cur = proj_unit(x_raw)\n",
    "    \n",
    "        val = f(x_cur)\n",
    "    \n",
    "        if val < f_best:\n",
    "            x_best = x_cur\n",
    "            f_best = val\n",
    "        \n",
    "        vals.append(val)\n",
    "    vals = np.array(vals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv',  header=None)\n",
    "a_list = data.values\n",
    "x_list = np.ones(len(a_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
