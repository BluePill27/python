{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yandex.Algorithm ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый из файлов субтитров в датасете OpenSubtitles [2], который мы использовали в качестве источника реплик и разговоров, содержит упорядоченный набор реплик. В большинстве случаев, каждая реплика – это ответ на предыдущую, в разговоре между двумя персонажами фильма. Мы случайно выбрали эпизоды этих разговоров в качестве наших тренировочных и тестовых примеров.\n",
    "\n",
    "Каждый эпизод состоит из двух частей – контекста (Context) и финальной реплики (Reply). Например,\n",
    "\n",
    "- context_2: Персонаж A говорит реплику \n",
    "\n",
    "- context_1: Персонаж B отвечает на нее \n",
    "\n",
    "- context_0: Персонаж А произносит вторую реплику \n",
    "\n",
    "reply: Персонаж B отвечает на вторую реплику \n",
    "Контекстная часть может состоять из трех реплик (как в примере) – в 50% случаев, двух – в 25%, и одного – в оставшихся 25% случаев. Финальная реплика (Reply) всегда завершает любой эпизод, то есть следует за контекстом (Context). Задача участников – найти наиболее подходящую и интересную реплику для данного контекста среди предложенных кандидатов (числом до 6), случайно выбранных из топа кандидатов, возвращенных бейзлайном высокого качества, натренированным командой Алисы (который, в свою очередь, отобрал кандидатов среди всех возможных реплик OpenSubtitles).\n",
    "\n",
    "Все реплики-кандидаты размечены асессорами на сервисе Яндекс.Толока с помощью следующей инструкции для разметки:\n",
    "\n",
    "- Good (2): реплика уместна (имеет смысл для данного контекста) и интересна (нетривиальна, специфична именно для данного контекста, мотивирует продолжать разговор)\n",
    "\n",
    "- Neutral (1): реплика уместна (имеет смысл для данного контекста), но не интересна (тривиальна, не специфична для данного контекста и скорее подталкивает пользователя закончить разговор)\n",
    "\n",
    "- Bad (0): реплика не имеет никакого смысла в данном контексте\n",
    "\n",
    "Каждая метка в тренировочной части датасета (и только в ней), сопровождается также уверенностью (confidence) – числом в интервале от 0 до 1 – которое показывает насколько уверенными в своей разметке были асессоры с Толоки, совместно предложившие данную метку. Мы хотим обратить особое внимание участников на эту информацию, она может быть очень полезна при обучении их моделей.\n",
    "\n",
    "Мы хотим особо отметить, что все участники имеют право скачать датасет OpenSubtitles [2], который использовался для подготовки датасета и применять его для тренировки своих моделей по своему усмотрению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T12:36:45.973220Z",
     "start_time": "2018-04-14T12:36:45.770991Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T20:08:49.456254Z",
     "start_time": "2018-04-12T20:08:49.346371Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- context_id – идентификатор эпизода\n",
    "- context_2,context_1,context_0 – текст реплик, предшествующих финальной (может состоять из трех частей)\n",
    "- reply_id – идентификатор реплики-кандидата\n",
    "- reply – текст реплики-кандидата\n",
    "- label – метка реплики-кандидата (good, neutral или bad)\n",
    "- confidence - уверенность в метке реплики-кандидата (число от 0 до 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T12:36:46.198075Z",
     "start_time": "2018-04-14T12:36:46.013912Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.tsv', sep='\\t', quotechar=' ', header = None)\n",
    "df.columns = ['context_id', 'context_2', 'context_1', 'context_0', 'reply_id', 'reply', 'label', 'confidence']\n",
    "test = pd.read_csv('data/public.tsv', sep='\\t', quotechar = ' ', header = None)\n",
    "test.columns = ['context_id', 'context_2', 'context_1', 'context_0', 'reply_id', 'reply']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T20:08:49.697885Z",
     "start_time": "2018-04-12T20:08:49.688309Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T20:08:49.718919Z",
     "start_time": "2018-04-12T20:08:49.699054Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y - label, and prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T12:36:46.318173Z",
     "start_time": "2018-04-14T12:36:46.310014Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def label_enc(x ,reverse = False):\n",
    "    if reverse == False:\n",
    "        if x == 'bad':\n",
    "            return 0\n",
    "        elif x == 'neutral':\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    else:\n",
    "        if x == 0:\n",
    "            return 'bad'\n",
    "        elif x == 1:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T12:36:46.465305Z",
     "start_time": "2018-04-14T12:36:46.387800Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(lambda x: label_enc(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T12:36:46.744135Z",
     "start_time": "2018-04-14T12:36:46.570064Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T12:36:46.867452Z",
     "start_time": "2018-04-14T12:36:46.856534Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def DCG(label): return sum([float(label[i]/np.log2(i+2)) for i in range(len(label))])\n",
    "\n",
    "def nDCG(label, best_label):\n",
    "    label, best_label = DCG(label), DCG(best_label)\n",
    "    if label != 0 and best_label != 0:\n",
    "        return label/best_label\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "scorer = make_scorer(nDCG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Nan clearing\n",
    "Wanted more clever way to dell and fill nan, but dropna or fillna, will work good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T12:36:47.043056Z",
     "start_time": "2018-04-14T12:36:46.970645Z"
    },
    "hidden": true,
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "df.fillna('-', inplace=True)\n",
    "test.fillna('-', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T12:36:47.472128Z",
     "start_time": "2018-04-14T12:36:47.173115Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "import scipy.sparse as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T12:36:47.652328Z",
     "start_time": "2018-04-14T12:36:47.646476Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def pre(s):\n",
    "    return re.sub(r'[^\\w]', ' ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T12:36:59.673875Z",
     "start_time": "2018-04-14T12:36:47.771613Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def Vect(df, test, use_idf=True, min_df=1, max_df=1.0, ngram_range = (1,8)):\n",
    "    v = []\n",
    "    if use_idf == True:\n",
    "        tfidf = TfidfVectorizer(stop_words=None, preprocessor=pre,\n",
    "                               ngram_range=ngram_range, strip_accents='unicode', analyzer='word',\n",
    "                               min_df = min_df, max_df=max_df)\n",
    "    \n",
    "        context_0 = tfidf.fit_transform(df['context_0'])\n",
    "        context_0_t = tfidf.transform(test['context_0'])\n",
    "        v.append(tfidf)\n",
    "    \n",
    "        context_1 = tfidf.fit_transform(df['context_1'])\n",
    "        context_1_t = tfidf.transform(test['context_1'])\n",
    "        v.append(tfidf)\n",
    "        \n",
    "        context_2 = tfidf.fit_transform(df['context_2'])\n",
    "        context_2_t = tfidf.transform(test['context_1'])\n",
    "        v.append(tfidf)\n",
    "        \n",
    "        reply = tfidf.fit_transform(df['reply'])\n",
    "        reply_t = tfidf.transform(test['reply'])\n",
    "        v.append(tfidf)\n",
    "        \n",
    "        return sps.hstack((context_0, context_1, context_2, reply)), \\\n",
    "               sps.hstack((context_0_t, context_1_t, context_2_t, reply_t)), v\n",
    "    else:\n",
    "        tf = CountVectorizer(stop_words=None, preprocessor=pre,\n",
    "                             ngram_range=ngram_range, strip_accents='unicode', analyzer='word',\n",
    "                             min_df = min_df, max_df=max_df)\n",
    "\n",
    "        context_0 = tf.fit_transform(df['context_0'])\n",
    "        context_0_t = tf.transform(test['context_0'])\n",
    "        v.append(tf)\n",
    "    \n",
    "        context_1 = tf.fit_transform(df['context_1'])\n",
    "        context_1_t = tf.transform(test['context_1'])\n",
    "        v.append(tf)\n",
    "        \n",
    "        context_2 = tf.fit_transform(df['context_2'])\n",
    "        context_2_t = tf.transform(test['context_1'])\n",
    "        v.append(tf)\n",
    "        \n",
    "        reply = tf.fit_transform(df['reply'])\n",
    "        reply_t = tf.transform(test['reply'])\n",
    "        v.append(tf)\n",
    "    \n",
    "        return sps.hstack((context_0, context_1, context_2, reply)), \\\n",
    "               sps.hstack((context_0_t, context_1_t, context_2_t, reply_t)), v\n",
    "\n",
    "X_train_tf, X_test_tf, tf_m = Vect(df, test, use_idf=False, max_df=0.80, min_df=8)\n",
    "X_train_tfidf, X_test_tfidf, tf_m = Vect(df, test, max_df=0.80, min_df=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T08:20:22.351592Z",
     "start_time": "2018-04-13T08:20:22.347246Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T20:08:54.415546Z",
     "start_time": "2018-04-12T20:08:54.390344Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation,TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-12T20:08:47.517Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "n_topics = 10\n",
    "\n",
    "def get_lda(data, test, topics):\n",
    "    lda = LatentDirichletAllocation(n_topics=topics, n_jobs=-1, learning_method='batch',\n",
    "                                   verbose = True).fit(data)\n",
    "    train = lda.transform(data)\n",
    "    test = lda.transform(test)\n",
    "    \n",
    "    return train, test, lda\n",
    "\n",
    "def get_kmeans(data, test, k, scale=True):\n",
    "    if scale == True:\n",
    "        scaler = MinMaxScaler().fit(data)\n",
    "        train = scaler.transform(data)\n",
    "        test = scale.transform(test)        \n",
    "    \n",
    "    kmean = KMeans(n_clusters=k).fit(data)\n",
    "    \n",
    "    train = kmean.predict(data)\n",
    "    test = kmean.predict(test)      \n",
    "    \n",
    "    return train, test, kmean    \n",
    "\n",
    "X_train_lda, X_train_lda, lda_m = get_lda(X_train_tf, X_test_tf, n_topics)\n",
    "X_train_m, X_test_m, kmean_m = get_kmeans(X_train_tfidf, X_test_tfidf, n_topics, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### decomposion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-12T20:08:47.520Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-12T20:08:47.523Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def SVD(X_train, X_test):\n",
    "    svd = TruncatedSVD(n_components=4, n_iter = 50)\n",
    "    svd = TruncatedSVD().fit(X_train)\n",
    "    \n",
    "    X_train = sps.hstack((svd.transform(X_train), X_train))\n",
    "    X_test = sps.hstack((svd.transform(X_test), X_test))\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "X_train, X_test = SVD(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:51:00.034698Z",
     "start_time": "2018-04-08T13:51:00.031784Z"
    }
   },
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T12:36:59.921097Z",
     "start_time": "2018-04-14T12:36:59.857413Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T20:13:37.255565Z",
     "start_time": "2018-04-13T20:13:37.247208Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_cv(X, y):\n",
    "    cv = StratifiedKFold(n_splits=6)\n",
    "    results = {\n",
    "        'lr': [],\n",
    "        'dtc': [],\n",
    "        'nb': [],\n",
    "        'xgb': [],\n",
    "        'adb': [],\n",
    "        'etr': [],\n",
    "        'kn': [],\n",
    "        'rf': [],\n",
    "        'bag': [],\n",
    "        'sgd': [],\n",
    "        'combined': []\n",
    "    }\n",
    "    \n",
    "    lm = LogisticRegression()\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    nb = MultinomialNB()\n",
    "    xgb = XGBClassifier()\n",
    "    adb = AdaBoostClassifier()\n",
    "    etr = ExtraTreesClassifier()\n",
    "    kn = KNeighborsClassifier()\n",
    "    rf = RandomForestClassifier()\n",
    "    bag = BaggingClassifier()\n",
    "    sgd = SGDClassifier()\n",
    "    vc = VotingClassifier([('lm', lm), ('dtc', dtc), ('nb', nb), \n",
    "                           ('xgb', xgb), ('adb', adb), ('etr', etr),\n",
    "                           ('kn', kn), ('rf', rf), ('bag', bag),\n",
    "                           ('sgd', sgd)])\n",
    "    \n",
    "    for c in tqdm_notebook([0,1,2]):\n",
    "        y_adj = np.array(y==c)\n",
    "        results['lr'].append((cross_val_score(lm, X, y_adj, cv=cv, scoring='accuracy', n_jobs=-1).mean(), c))\n",
    "        results['dtc'].append((cross_val_score(dtc, X, y_adj, cv=cv, scoring='accuracy', n_jobs=-1).mean(), c))\n",
    "        results['nb'].append((cross_val_score(nb, X, y_adj, cv=cv, scoring='accuracy', n_jobs=-1).mean(), c))\n",
    "        results['xgb'].append((cross_val_score(xgb, X, y_adj, cv=cv, scoring='accuracy', n_jobs=-1).mean(), c))\n",
    "        results['adb'].append((cross_val_score(adb, X, y_adj, cv=cv, scoring='accuracy', n_jobs=-1).mean(), c))\n",
    "        results['etr'].append((cross_val_score(etr, X, y_adj, cv=cv, scoring='accuracy', n_jobs=-1).mean(), c))\n",
    "        results['kn'].append((cross_val_score(kn, X, y_adj, cv=cv, scoring='accuracy', n_jobs=-1).mean(), c))\n",
    "        results['rf'].append((cross_val_score(rf, X, y_adj, cv=cv, scoring='accuracy', n_jobs=-1).mean(), c))\n",
    "        results['bag'].append((cross_val_score(bag, X, y_adj, cv=cv, scoring='accuracy', n_jobs=-1).mean(), c))\n",
    "        results['sgd'].append((cross_val_score(sgd, X, y_adj, cv=cv, scoring='accuracy', n_jobs=-1).mean(), c))\n",
    "        results['combined'].append((cross_val_score(vc, X, y_adj, cv=cv, scoring='accuracy', n_jobs=-1).mean(), c))\n",
    "    \n",
    "    print(\"Model accuracy predictions\\n\")\n",
    "    for m,s in list(results.items()):\n",
    "        for ss in s:\n",
    "            print((\"{M} model ({R} rating): {S:.1%}\".format(M=m.upper(), R=ss[1], S=ss[0])))\n",
    "            print()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T20:29:58.801551Z",
     "start_time": "2018-04-13T20:13:37.307296Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, df['label'], test_size=0.3)\n",
    "r1 = calculate_cv(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-13T20:57:44.755815Z",
     "start_time": "2018-04-13T20:43:49.752772Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tf, df['label'], test_size=0.3)\n",
    "r2 = calculate_cv(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T12:37:00.024015Z",
     "start_time": "2018-04-14T12:37:00.017452Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T12:39:12.463381Z",
     "start_time": "2018-04-14T12:39:00.251514Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 68273 samples, validate on 29260 samples\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,33926,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_4/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/embedding_4/GatherV2_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_4/embeddings/read, embedding_4/Cast, bidirectional_4/TensorArrayUnstack_1/range/start)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_3/mul/_415 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3201_loss_3/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'embedding_4/GatherV2', defined at:\n  File \"/home/denis/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/denis/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/denis/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/denis/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/denis/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-55fdb6ad56ec>\", line 8, in <module>\n    model.add(Embedding(10000, 128, input_length=maxlen))\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/keras/models.py\", line 467, in add\n    layer(x)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1211, in gather\n    return tf.gather(reference, indices)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,33926,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_4/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/embedding_4/GatherV2_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_4/embeddings/read, embedding_4/Cast, bidirectional_4/TensorArrayUnstack_1/range/start)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_3/mul/_415 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3201_loss_3/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,33926,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_4/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/embedding_4/GatherV2_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_4/embeddings/read, embedding_4/Cast, bidirectional_4/TensorArrayUnstack_1/range/start)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_3/mul/_415 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3201_loss_3/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-55fdb6ad56ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m               validation_data=[X_test, y_test])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,33926,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_4/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/embedding_4/GatherV2_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_4/embeddings/read, embedding_4/Cast, bidirectional_4/TensorArrayUnstack_1/range/start)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_3/mul/_415 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3201_loss_3/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'embedding_4/GatherV2', defined at:\n  File \"/home/denis/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/denis/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/denis/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/denis/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/denis/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-55fdb6ad56ec>\", line 8, in <module>\n    model.add(Embedding(10000, 128, input_length=maxlen))\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/keras/models.py\", line 467, in add\n    layer(x)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1211, in gather\n    return tf.gather(reference, indices)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/denis/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,33926,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_4/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/embedding_4/GatherV2_grad/Reshape\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_4/embeddings/read, embedding_4/Cast, bidirectional_4/TensorArrayUnstack_1/range/start)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_3/mul/_415 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3201_loss_3/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "maxlen = 100\n",
    "batch_size = 32\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tf, df['label'], test_size=0.3)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(10000, 128, input_length=maxlen))\n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print('Train...')\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=4,\n",
    "              validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T06:59:31.880976Z",
     "start_time": "2018-04-14T06:59:31.878846Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def decis(prob0, prob1, prob2):\n",
    "    if prob0 > prob1 and prob0 > prob2:\n",
    "        return [prob0, 0]\n",
    "    elif prob0 < prob1 and prob1 > prob2:\n",
    "        return [prob1, 1]\n",
    "    else:\n",
    "        return [prob2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T06:59:31.959113Z",
     "start_time": "2018-04-14T06:59:31.953716Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def predict(X_train, y ,X_test):\n",
    "    lm = LogisticRegression(class_weight='balanced')\n",
    "    dtc = DecisionTreeClassifier(class_weight='balanced')\n",
    "    nb = MultinomialNB()\n",
    "    xgb = XGBClassifier()\n",
    "    adb = AdaBoostClassifier()\n",
    "    etr = ExtraTreesClassifier(class_weight='balanced')\n",
    "    kn = KNeighborsClassifier(n_neighbors=10)\n",
    "    rf = RandomForestClassifier(class_weight='balanced')\n",
    "    bag = BaggingClassifier()\n",
    "    sgd = SGDClassifier(class_weight='balanced', loss='log', n_jobs=-1)\n",
    "    vc = VotingClassifier([('lm', lm), ('dtc', dtc), ('nb', nb), \n",
    "                           ('xgb', xgb), ('adb', adb), ('etr', etr),\n",
    "                           ('kn', kn), ('rf', rf), ('bag', bag),\n",
    "                           ('sgd', sgd)], n_jobs=-1, voting = 'soft')\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "    for c in tqdm_notebook([0,1,2]):\n",
    "        y_adj = np.array(y==c)\n",
    "        vc.fit(X_train, y_adj)\n",
    "        result['pred'+str(c)] = vc.predict(X_test)\n",
    "        result['proba'+str(c)] = vc.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    result['label'] = result.apply(lambda row: decis(row['proba0'], row['proba1'], row['proba2'])[1] ,axis=1)\n",
    "    result['confidence'] = result.apply(lambda row: decis(row['proba0'], row['proba1'], row['proba2'])[0] ,axis=1)\n",
    "    \n",
    "    return result[['label', 'confidence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T07:26:00.471115Z",
     "start_time": "2018-04-14T06:59:32.034524Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1dfe808d62476b90cfd5dfe1c88c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/denis/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/denis/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = predict(X_train_tfidf, df['label'], X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T07:26:00.581041Z",
     "start_time": "2018-04-14T07:26:00.522700Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "test['confidence'] = result['confidence']\n",
    "test['label']  = result['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-14T07:35:33.441Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "test.sort_values(by=['context_id', 'confidence'])[['context_id', 'reply_id']].to_csv('subm.csv', encoding='utf-8', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
